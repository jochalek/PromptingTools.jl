<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · PromptingTools.jl</title><meta name="title" content="Home · PromptingTools.jl"/><meta property="og:title" content="Home · PromptingTools.jl"/><meta property="twitter:title" content="Home · PromptingTools.jl"/><meta name="description" content="Documentation for PromptingTools.jl."/><meta property="og:description" content="Documentation for PromptingTools.jl."/><meta property="twitter:description" content="Documentation for PromptingTools.jl."/><meta property="og:url" content="https://svilupp.github.io/PromptingTools.jl/"/><meta property="twitter:url" content="https://svilupp.github.io/PromptingTools.jl/"/><link rel="canonical" href="https://svilupp.github.io/PromptingTools.jl/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>PromptingTools.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/svilupp/PromptingTools.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/svilupp/PromptingTools.jl/blob/main/docs/src/index.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="PromptingTools"><a class="docs-heading-anchor" href="#PromptingTools">PromptingTools</a><a id="PromptingTools-1"></a><a class="docs-heading-anchor-permalink" href="#PromptingTools" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/svilupp/PromptingTools.jl">PromptingTools</a>.</p><ul><li><a href="#PromptingTools.AITemplate"><code>PromptingTools.AITemplate</code></a></li><li><a href="#PromptingTools.AITemplateMetadata"><code>PromptingTools.AITemplateMetadata</code></a></li><li><a href="#PromptingTools.AbstractPromptSchema"><code>PromptingTools.AbstractPromptSchema</code></a></li><li><a href="#PromptingTools.ChatMLSchema"><code>PromptingTools.ChatMLSchema</code></a></li><li><a href="#PromptingTools.OllamaManagedSchema"><code>PromptingTools.OllamaManagedSchema</code></a></li><li><a href="#PromptingTools.OpenAISchema"><code>PromptingTools.OpenAISchema</code></a></li><li><a href="#PromptingTools.TestEchoOpenAISchema"><code>PromptingTools.TestEchoOpenAISchema</code></a></li><li><a href="#PromptingTools.aiclassify-Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, PromptingTools.AbstractMessage, Vector{&lt;:PromptingTools.AbstractMessage}}}"><code>PromptingTools.aiclassify</code></a></li><li><a href="#PromptingTools.aiembed-Union{Tuple{F}, Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, Vector{&lt;:AbstractString}}}, Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, Vector{&lt;:AbstractString}}, F}} where F&lt;:Function"><code>PromptingTools.aiembed</code></a></li><li><a href="#PromptingTools.aigenerate-Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, PromptingTools.AbstractMessage, Vector{&lt;:PromptingTools.AbstractMessage}}}"><code>PromptingTools.aigenerate</code></a></li><li><a href="#PromptingTools.aitemplates-Tuple{Symbol}"><code>PromptingTools.aitemplates</code></a></li><li><a href="#PromptingTools.aitemplates-Tuple{Regex}"><code>PromptingTools.aitemplates</code></a></li><li><a href="#PromptingTools.aitemplates"><code>PromptingTools.aitemplates</code></a></li><li><a href="#PromptingTools.aitemplates-Tuple{AbstractString}"><code>PromptingTools.aitemplates</code></a></li><li><a href="#PromptingTools.load_template-Tuple{Union{AbstractString, IO}}"><code>PromptingTools.load_template</code></a></li><li><a href="#PromptingTools.load_templates!"><code>PromptingTools.load_templates!</code></a></li><li><a href="#PromptingTools.remove_templates!-Tuple{}"><code>PromptingTools.remove_templates!</code></a></li><li><a href="#PromptingTools.render-Tuple{PromptingTools.AbstractOpenAISchema, Vector{&lt;:PromptingTools.AbstractMessage}}"><code>PromptingTools.render</code></a></li><li><a href="#PromptingTools.render-Tuple{AITemplate}"><code>PromptingTools.render</code></a></li><li><a href="#PromptingTools.save_template-Tuple{Union{AbstractString, IO}, AbstractVector{&lt;:PromptingTools.AbstractChatMessage}}"><code>PromptingTools.save_template</code></a></li><li><a href="#PromptingTools.@aai_str-Tuple{Any, Vararg{Any}}"><code>PromptingTools.@aai_str</code></a></li><li><a href="#PromptingTools.@ai_str-Tuple{Any, Vararg{Any}}"><code>PromptingTools.@ai_str</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.AITemplate" href="#PromptingTools.AITemplate"><code>PromptingTools.AITemplate</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">AITemplate</code></pre><p>AITemplate is a template for a conversation prompt.   This type is merely a container for the template name, which is resolved into a set of messages (=prompt) by <code>render</code>.</p><p><strong>Naming Convention</strong></p><ul><li>Template names should be in CamelCase</li><li>Follow the format <code>&lt;Persona&gt;...&lt;Variable&gt;...</code> where possible, eg, <code>JudgeIsItTrue</code>, ``<ul><li>Starting with the Persona (=System prompt), eg, <code>Judge</code> = persona is meant to <code>judge</code> some provided information</li><li>Variable to be filled in with context, eg, <code>It</code> = placeholder <code>it</code></li><li>Ending with the variable name is helpful, eg, <code>JuliaExpertTask</code> for a persona to be an expert in Julia language and <code>task</code> is the placeholder name</li></ul></li><li>Ideally, the template name should be self-explanatory, eg, <code>JudgeIsItTrue</code> = persona is meant to <code>judge</code> some provided information where it is true or false</li></ul><p><strong>Examples</strong></p><p>Save time by re-using pre-made templates, just fill in the placeholders with the keyword arguments:</p><pre><code class="language-julia hljs">msg = aigenerate(:JuliaExpertAsk; ask = &quot;How do I add packages?&quot;)</code></pre><p>The above is equivalent to a more verbose version that explicitly uses the dispatch on <code>AITemplate</code>:</p><pre><code class="language-julia hljs">msg = aigenerate(AITemplate(:JuliaExpertAsk); ask = &quot;How do I add packages?&quot;)</code></pre><p>Find available templates with <code>aitemplates</code>:</p><pre><code class="language-julia hljs">tmps = aitemplates(&quot;JuliaExpertAsk&quot;)
# Will surface one specific template
# 1-element Vector{AITemplateMetadata}:
# PromptingTools.AITemplateMetadata
#   name: Symbol JuliaExpertAsk
#   description: String &quot;For asking questions about Julia language. Placeholders: `ask`&quot;
#   version: String &quot;1&quot;
#   wordcount: Int64 237
#   variables: Array{Symbol}((1,))
#   system_preview: String &quot;You are a world-class Julia language programmer with the knowledge of the latest syntax. Your commun&quot;
#   user_preview: String &quot;# Question

{{ask}}&quot;
#   source: String &quot;&quot;</code></pre><p>The above gives you a good idea of what the template is about, what placeholders are available, and how much it would cost to use it (=wordcount).</p><p>Search for all Julia-related templates:</p><pre><code class="language-julia hljs">tmps = aitemplates(&quot;Julia&quot;)
# 2-element Vector{AITemplateMetadata}... -&gt; more to come later!</code></pre><p>If you are on VSCode, you can leverage nice tabular display with <code>vscodedisplay</code>:</p><pre><code class="language-julia hljs">using DataFrames
tmps = aitemplates(&quot;Julia&quot;) |&gt; DataFrame |&gt; vscodedisplay</code></pre><p>I have my selected template, how do I use it? Just use the &quot;name&quot; in <code>aigenerate</code> or <code>aiclassify</code>   like you see in the first example!</p><p>You can inspect any template by &quot;rendering&quot; it (this is what the LLM will see):</p><pre><code class="language-julia hljs">julia&gt; AITemplate(:JudgeIsItTrue) |&gt; PromptingTools.render</code></pre><p>See also: <code>save_template</code>, <code>load_template</code>, <code>load_templates!</code> for more advanced use cases (and the corresponding script in <code>examples/</code> folder)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L8-L74">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.AITemplateMetadata" href="#PromptingTools.AITemplateMetadata"><code>PromptingTools.AITemplateMetadata</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Helper for easy searching and reviewing of templates. Defined on loading of each template.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L77">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.AbstractPromptSchema" href="#PromptingTools.AbstractPromptSchema"><code>PromptingTools.AbstractPromptSchema</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Defines different prompting styles based on the model training and fine-tuning.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/llm_interface.jl#L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.ChatMLSchema" href="#PromptingTools.ChatMLSchema"><code>PromptingTools.ChatMLSchema</code></a> — <span class="docstring-category">Type</span></header><section><div><p>ChatMLSchema is used by many open-source chatbots, by OpenAI models (under the hood) and by several models and inferfaces (eg, Ollama, vLLM)</p><p>You can explore it on <a href="https://tiktokenizer.vercel.app/">tiktokenizer</a></p><p>It uses the following conversation structure:</p><pre><code class="nohighlight hljs">&lt;im_start&gt;system
...&lt;im_end&gt;
&lt;|im_start|&gt;user
...&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
...&lt;|im_end|&gt;</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/llm_interface.jl#L42-L56">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.OllamaManagedSchema" href="#PromptingTools.OllamaManagedSchema"><code>PromptingTools.OllamaManagedSchema</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Ollama by default manages different models and their associated prompt schemas when you pass <code>system_prompt</code> and <code>prompt</code> fields to the API.</p><p>Warning: It works only for 1 system message and 1 user message, so anything more than that has to be rejected.</p><p>If you need to pass more messagese / longer conversational history, you can use define the model-specific schema directly and pass your Ollama requests with <code>raw=true</code>,   which disables and templating and schema management by Ollama.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/llm_interface.jl#L61-L68">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.OpenAISchema" href="#PromptingTools.OpenAISchema"><code>PromptingTools.OpenAISchema</code></a> — <span class="docstring-category">Type</span></header><section><div><p>OpenAISchema is the default schema for OpenAI models.</p><p>It uses the following conversation template:</p><pre><code class="nohighlight hljs">[Dict(role=&quot;system&quot;,content=&quot;...&quot;),Dict(role=&quot;user&quot;,content=&quot;...&quot;),Dict(role=&quot;assistant&quot;,content=&quot;...&quot;)]</code></pre><p>It&#39;s recommended to separate sections in your prompt with markdown headers (e.g. `##Answer</p><p>`).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/llm_interface.jl#L21-L32">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.TestEchoOpenAISchema" href="#PromptingTools.TestEchoOpenAISchema"><code>PromptingTools.TestEchoOpenAISchema</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Echoes the user&#39;s input back to them. Used for testing the implementation</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/llm_interface.jl#L33">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.aiclassify-Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, PromptingTools.AbstractMessage, Vector{&lt;:PromptingTools.AbstractMessage}}}" href="#PromptingTools.aiclassify-Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, PromptingTools.AbstractMessage, Vector{&lt;:PromptingTools.AbstractMessage}}}"><code>PromptingTools.aiclassify</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">aiclassify(prompt_schema::AbstractOpenAISchema, prompt::ALLOWED_PROMPT_TYPE;
api_kwargs::NamedTuple = (logit_bias = Dict(837 =&gt; 100, 905 =&gt; 100, 9987 =&gt; 100),
    max_tokens = 1, temperature = 0),
kwargs...)</code></pre><p>Classifies the given prompt/statement as true/false/unknown.</p><p>Note: this is a very simple classifier, it is not meant to be used in production. Credit goes to <a href="https://twitter.com/AAAzzam/status/1669753721574633473">AAAzzam</a>.</p><p>It uses Logit bias trick and limits the output to 1 token to force the model to output only true/false/unknown.</p><p>Output tokens used (via <code>api_kwargs</code>):</p><ul><li>837: &#39; true&#39;</li><li>905: &#39; false&#39;</li><li>9987: &#39; unknown&#39;</li></ul><p><strong>Arguments</strong></p><ul><li><code>prompt_schema::AbstractOpenAISchema</code>: The schema for the prompt.</li><li><code>prompt</code>: The prompt/statement to classify if it&#39;s a <code>String</code>. If it&#39;s a <code>Symbol</code>, it is expanded as a template via <code>render(schema,template)</code>.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">aiclassify(&quot;Is two plus two four?&quot;) # true
aiclassify(&quot;Is two plus three a vegetable on Mars?&quot;) # false</code></pre><p><code>aiclassify</code> returns only true/false/unknown. It&#39;s easy to get the proper <code>Bool</code> output type out with <code>tryparse</code>, eg,</p><pre><code class="language-julia hljs">tryparse(Bool, aiclassify(&quot;Is two plus two four?&quot;)) isa Bool # true</code></pre><p>Output of type <code>Nothing</code> marks that the model couldn&#39;t classify the statement as true/false.</p><p>Ideally, we would like to re-use some helpful system prompt to get more accurate responses. For this reason we have templates, eg, <code>:JudgeIsItTrue</code>. By specifying the template, we can provide our statement as the expected variable (<code>it</code> in this case) See that the model now correctly classifies the statement as &quot;unknown&quot;.</p><pre><code class="language-julia hljs">aiclassify(:JudgeIsItTrue; it = &quot;Is two plus three a vegetable on Mars?&quot;) # unknown</code></pre><p>For better results, use higher quality models like gpt4, eg, </p><pre><code class="language-julia hljs">aiclassify(:JudgeIsItTrue;
    it = &quot;If I had two apples and I got three more, I have five apples now.&quot;,
    model = &quot;gpt4&quot;) # true</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/llm_openai.jl#L242-L289">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.aiembed-Union{Tuple{F}, Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, Vector{&lt;:AbstractString}}}, Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, Vector{&lt;:AbstractString}}, F}} where F&lt;:Function" href="#PromptingTools.aiembed-Union{Tuple{F}, Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, Vector{&lt;:AbstractString}}}, Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, Vector{&lt;:AbstractString}}, F}} where F&lt;:Function"><code>PromptingTools.aiembed</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">aiembed(prompt_schema::AbstractOpenAISchema,
        doc_or_docs::Union{AbstractString, Vector{&lt;:AbstractString}},
        postprocess::F = identity;
        verbose::Bool = true,
        api_key::String = API_KEY,
        model::String = MODEL_EMBEDDING,
        http_kwargs::NamedTuple = (retry_non_idempotent = true,
                                   retries = 5,
                                   readtimeout = 120),
        api_kwargs::NamedTuple = NamedTuple(),
        kwargs...) where {F &lt;: Function}</code></pre><p>The <code>aiembed</code> function generates embeddings for the given input using a specified model and returns a message object containing the embeddings, status, token count, and elapsed time.</p><p><strong>Arguments</strong></p><ul><li><code>prompt_schema::AbstractOpenAISchema</code>: The schema for the prompt.</li><li><code>doc_or_docs::Union{AbstractString, Vector{&lt;:AbstractString}}</code>: The document or list of documents to generate embeddings for.</li><li><code>postprocess::F</code>: The post-processing function to apply to each embedding. Defaults to the identity function.</li><li><code>verbose::Bool</code>: A flag indicating whether to print verbose information. Defaults to <code>true</code>.</li><li><code>api_key::String</code>: The API key to use for the OpenAI API. Defaults to <code>API_KEY</code>.</li><li><code>model::String</code>: The model to use for generating embeddings. Defaults to <code>MODEL_EMBEDDING</code>.</li><li><code>http_kwargs::NamedTuple</code>: Additional keyword arguments for the HTTP request. Defaults to <code>(retry_non_idempotent = true, retries = 5, readtimeout = 120)</code>.</li><li><code>api_kwargs::NamedTuple</code>: Additional keyword arguments for the OpenAI API. Defaults to an empty <code>NamedTuple</code>.</li><li><code>kwargs...</code>: Additional keyword arguments.</li></ul><p><strong>Returns</strong></p><ul><li><code>msg</code>: A <code>DataMessage</code> object containing the embeddings, status, token count, and elapsed time.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">msg = aiembed(&quot;Hello World&quot;)
msg.content # 1536-element JSON3.Array{Float64...</code></pre><p>We can embed multiple strings at once and they will be <code>hcat</code> into a matrix   (ie, each column corresponds to one string)</p><pre><code class="language-julia hljs">msg = aiembed([&quot;Hello World&quot;, &quot;How are you?&quot;])
msg.content # 1536×2 Matrix{Float64}:</code></pre><p>If you plan to calculate the cosine distance between embeddings, you can normalize them first:</p><pre><code class="language-julia hljs">using LinearAlgebra
msg = aiembed([&quot;embed me&quot;, &quot;and me too&quot;], LinearAlgebra.normalize)

# calculate cosine distance between the two normalized embeddings as a simple dot product
msg.content&#39; * msg.content[:, 1] # [1.0, 0.787]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/llm_openai.jl#L144-L196">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.aigenerate-Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, PromptingTools.AbstractMessage, Vector{&lt;:PromptingTools.AbstractMessage}}}" href="#PromptingTools.aigenerate-Tuple{PromptingTools.AbstractOpenAISchema, Union{AbstractString, PromptingTools.AbstractMessage, Vector{&lt;:PromptingTools.AbstractMessage}}}"><code>PromptingTools.aigenerate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">aigenerate([prompt_schema::AbstractOpenAISchema,] prompt::ALLOWED_PROMPT_TYPE; verbose::Bool = true,
    model::String = MODEL_CHAT,
    http_kwargs::NamedTuple = (;
        retry_non_idempotent = true,
        retries = 5,
        readtimeout = 120), api_kwargs::NamedTuple = NamedTuple(),
    kwargs...)</code></pre><p>Generate an AI response based on a given prompt using the OpenAI API.</p><p><strong>Arguments</strong></p><ul><li><code>prompt_schema</code>: An optional object to specify which prompt template should be applied (Default to <code>PROMPT_SCHEMA = OpenAISchema</code>)</li><li><code>prompt</code>: Can be a string representing the prompt for the AI conversation, a <code>UserMessage</code>, a vector of <code>AbstractMessage</code> or an <code>AITemplate</code></li><li><code>verbose</code>: A boolean indicating whether to print additional information.</li><li><code>prompt_schema</code>: An abstract schema for the prompt.</li><li><code>api_key</code>: A string representing the API key for accessing the OpenAI API.</li><li><code>model</code>: A string representing the model to use for generating the response. Can be an alias corresponding to a model ID defined in <code>MODEL_ALIASES</code>.</li><li><code>http_kwargs</code>: A named tuple of HTTP keyword arguments.</li><li><code>api_kwargs</code>: A named tuple of API keyword arguments.</li><li><code>kwargs</code>: Prompt variables to be used to fill the prompt/template</li></ul><p><strong>Returns</strong></p><ul><li><code>msg</code>: An <code>AIMessage</code> object representing the generated AI message, including the content, status, tokens, and elapsed time.</li></ul><p>See also: <code>ai_str</code></p><p><strong>Example</strong></p><p>Simple hello world to test the API:</p><pre><code class="language-julia hljs">result = aigenerate(&quot;Say Hi!&quot;)
# [ Info: Tokens: 29 @ Cost: $0.0 in 1.0 seconds
# AIMessage(&quot;Hello! How can I assist you today?&quot;)</code></pre><p><code>result</code> is an <code>AIMessage</code> object. Access the generated string via <code>content</code> property:</p><pre><code class="language-julia hljs">typeof(result) # AIMessage{SubString{String}}
propertynames(result) # (:content, :status, :tokens, :elapsed
result.content # &quot;Hello! How can I assist you today?&quot;</code></pre><p>___ You can use string interpolation:</p><pre><code class="language-julia hljs">a = 1
msg=aigenerate(&quot;What is `$a+$a`?&quot;)
msg.content # &quot;The sum of `1+1` is `2`.&quot;</code></pre><p>___ You can provide the whole conversation or more intricate prompts as a <code>Vector{AbstractMessage}</code>:</p><pre><code class="language-julia hljs">conversation = [
    SystemMessage(&quot;You&#39;re master Yoda from Star Wars trying to help the user become a Yedi.&quot;),
    UserMessage(&quot;I have feelings for my iPhone. What should I do?&quot;)]
msg=aigenerate(conversation)
# AIMessage(&quot;Ah, strong feelings you have for your iPhone. A Jedi&#39;s path, this is not... &lt;continues&gt;&quot;)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/llm_openai.jl#L41-L99">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.aitemplates" href="#PromptingTools.aitemplates"><code>PromptingTools.aitemplates</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">aitemplates</code></pre><p>Find easily the most suitable templates for your use case.</p><p>You can search by:</p><ul><li><code>query::Symbol</code> which looks look only for partial matches in the template <code>name</code></li><li><code>query::AbstractString</code> which looks for partial matches in the template <code>name</code> or <code>description</code></li><li><code>query::Regex</code> which looks for matches in the template <code>name</code>, <code>description</code> or any of the message previews</li></ul><p><strong>Keyword Arguments</strong></p><ul><li><code>limit::Int</code> limits the number of returned templates (Defaults to 10)</li></ul><p><strong>Examples</strong></p><p>Find available templates with <code>aitemplates</code>:</p><pre><code class="language-julia hljs">tmps = aitemplates(&quot;JuliaExpertAsk&quot;)
# Will surface one specific template
# 1-element Vector{AITemplateMetadata}:
# PromptingTools.AITemplateMetadata
#   name: Symbol JuliaExpertAsk
#   description: String &quot;For asking questions about Julia language. Placeholders: `ask`&quot;
#   version: String &quot;1&quot;
#   wordcount: Int64 237
#   variables: Array{Symbol}((1,))
#   system_preview: String &quot;You are a world-class Julia language programmer with the knowledge of the latest syntax. Your commun&quot;
#   user_preview: String &quot;# Question

{{ask}}&quot;
#   source: String &quot;&quot;</code></pre><p>The above gives you a good idea of what the template is about, what placeholders are available, and how much it would cost to use it (=wordcount).</p><p>Search for all Julia-related templates:</p><pre><code class="language-julia hljs">tmps = aitemplates(&quot;Julia&quot;)
# 2-element Vector{AITemplateMetadata}... -&gt; more to come later!</code></pre><p>If you are on VSCode, you can leverage nice tabular display with <code>vscodedisplay</code>:</p><pre><code class="language-julia hljs">using DataFrames
tmps = aitemplates(&quot;Julia&quot;) |&gt; DataFrame |&gt; vscodedisplay</code></pre><p>I have my selected template, how do I use it? Just use the &quot;name&quot; in <code>aigenerate</code> or <code>aiclassify</code>   like you see in the first example!</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L221-L269">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.aitemplates-Tuple{AbstractString}" href="#PromptingTools.aitemplates-Tuple{AbstractString}"><code>PromptingTools.aitemplates</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find the top-<code>limit</code> templates whose <code>name</code> or <code>description</code> fields partially match the <code>query_key::String</code> in <code>TEMPLATE_METADATA</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L279">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.aitemplates-Tuple{Regex}" href="#PromptingTools.aitemplates-Tuple{Regex}"><code>PromptingTools.aitemplates</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find the top-<code>limit</code> templates where provided <code>query_key::Regex</code> matches either of <code>name</code>, <code>description</code> or previews or User or System messages in <code>TEMPLATE_METADATA</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L289">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.aitemplates-Tuple{Symbol}" href="#PromptingTools.aitemplates-Tuple{Symbol}"><code>PromptingTools.aitemplates</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Find the top-<code>limit</code> templates whose <code>name::Symbol</code> partially matches the <code>query_name::Symbol</code> in <code>TEMPLATE_METADATA</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L270">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.load_template-Tuple{Union{AbstractString, IO}}" href="#PromptingTools.load_template-Tuple{Union{AbstractString, IO}}"><code>PromptingTools.load_template</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Loads messaging template from <code>io_or_file</code> and returns tuple of template messages and metadata.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L131">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.load_templates!" href="#PromptingTools.load_templates!"><code>PromptingTools.load_templates!</code></a> — <span class="docstring-category">Function</span></header><section><div><pre><code class="language-julia hljs">load_templates!(; remove_templates::Bool=true)</code></pre><p>Loads templates from folder <code>templates/</code> in the package root and stores them in <code>TEMPLATE_STORE</code> and <code>TEMPLATE_METADATA</code>.</p><p>Note: Automatically removes any existing templates and metadata from <code>TEMPLATE_STORE</code> and <code>TEMPLATE_METADATA</code> if <code>remove_templates=true</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L153-L159">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.remove_templates!-Tuple{}" href="#PromptingTools.remove_templates!-Tuple{}"><code>PromptingTools.remove_templates!</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">    remove_templates!()</code></pre><p>Removes all templates from <code>TEMPLATE_STORE</code> and <code>TEMPLATE_METADATA</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L146-L150">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.render-Tuple{AITemplate}" href="#PromptingTools.render-Tuple{AITemplate}"><code>PromptingTools.render</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Renders provided messaging template (<code>template</code>) under the default schema (<code>PROMPT_SCHEMA</code>).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L110">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.render-Tuple{PromptingTools.AbstractOpenAISchema, Vector{&lt;:PromptingTools.AbstractMessage}}" href="#PromptingTools.render-Tuple{PromptingTools.AbstractOpenAISchema, Vector{&lt;:PromptingTools.AbstractMessage}}"><code>PromptingTools.render</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Builds a history of the conversation to provide the prompt to the API. All kwargs are passed as replacements such that <code>{{key}}=&gt;value</code> in the template.}}</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/llm_openai.jl#L2">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.save_template-Tuple{Union{AbstractString, IO}, AbstractVector{&lt;:PromptingTools.AbstractChatMessage}}" href="#PromptingTools.save_template-Tuple{Union{AbstractString, IO}, AbstractVector{&lt;:PromptingTools.AbstractChatMessage}}"><code>PromptingTools.save_template</code></a> — <span class="docstring-category">Method</span></header><section><div><p>Saves provided messaging template (<code>messages</code>) to <code>io_or_file</code>. Automatically adds metadata based on provided keyword arguments.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/templates.jl#L117">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.@aai_str-Tuple{Any, Vararg{Any}}" href="#PromptingTools.@aai_str-Tuple{Any, Vararg{Any}}"><code>PromptingTools.@aai_str</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">aai&quot;user_prompt&quot;[model_alias] -&gt; AIMessage</code></pre><p>Asynchronous version of <code>@ai_str</code> macro, which will log the result once it&#39;s ready.</p><p><strong>Example</strong></p><p>Send asynchronous request to GPT-4, so we don&#39;t have to wait for the response: Very practical with slow models, so you can keep working in the meantime.</p><p>```julia m = aai&quot;Say Hi!&quot;gpt4; </p><p><strong>...with some delay...</strong></p><p><strong>[ Info: Tokens: 29 @ Cost: 0.0011 in 2.7 seconds</strong></p><p><strong>[ Info: AIMessage&gt; Hello! How can I assist you today?</strong></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/macros.jl#L40-L55">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="PromptingTools.@ai_str-Tuple{Any, Vararg{Any}}" href="#PromptingTools.@ai_str-Tuple{Any, Vararg{Any}}"><code>PromptingTools.@ai_str</code></a> — <span class="docstring-category">Macro</span></header><section><div><pre><code class="language-julia hljs">ai&quot;user_prompt&quot;[model_alias] -&gt; AIMessage</code></pre><p>The <code>ai&quot;&quot;</code> string macro generates an AI response to a given prompt by using <code>aigenerate</code> under the hood.</p><p><strong>Arguments</strong></p><ul><li><code>user_prompt</code> (String): The input prompt for the AI model.</li><li><code>model_alias</code> (optional, any): Provide model alias of the AI model (see <code>MODEL_ALIASES</code>).</li></ul><p><strong>Returns</strong></p><p><code>AIMessage</code> corresponding to the input prompt.</p><p><strong>Example</strong></p><pre><code class="language-julia hljs">result = ai&quot;Hello, how are you?&quot;
# AIMessage(&quot;Hello! I&#39;m an AI assistant, so I don&#39;t have feelings, but I&#39;m here to help you. How can I assist you today?&quot;)</code></pre><p>If you want to interpolate some variables or additional context, simply use string interpolation:</p><pre><code class="language-julia hljs">a=1
result = ai&quot;What is `$a+$a`?&quot;
# AIMessage(&quot;The sum of `1+1` is `2`.&quot;)</code></pre><p>If you want to use a different model, eg, GPT-4, you can provide its alias as a flag:</p><pre><code class="language-julia hljs">result = ai&quot;What is `1.23 * 100 + 1`?&quot;gpt4
# AIMessage(&quot;The answer is 124.&quot;)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/svilupp/PromptingTools.jl/blob/7f09e41aa92837e6c78a9241988f07bbe09fab5a/src/macros.jl#L1-L31">source</a></section></article></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.2 on <span class="colophon-date" title="Thursday 16 November 2023 07:10">Thursday 16 November 2023</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
